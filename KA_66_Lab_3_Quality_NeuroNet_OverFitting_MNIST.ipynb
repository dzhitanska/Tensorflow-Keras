{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yRBINkizxNEY"
   },
   "source": [
    "\n",
    "# **Оцінка якості навчання нейронної мережі в Keras**\n",
    "На прикладі розпізнавання рукописних цифр з набору даних MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 62
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11237,
     "status": "ok",
     "timestamp": 1572513989082,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "vKd7Eq3HxP59",
    "outputId": "54b0ca76-04e3-4893-e233-65f5b7bfe987"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.preprocessing import image\n",
    "#from google.colab import files\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "from tensorflow.python.keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B1sYB1gwxQVY"
   },
   "source": [
    "Підготовка даних для навчання мережі\n",
    "\n",
    "Завантажуємо набір даних з рукописними цифрами\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "io6uxLc2xQqx"
   },
   "outputs": [],
   "source": [
    "(x_train_org, y_train_org), (x_test_org, y_test_org) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1572514212560,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "wPzNHkuPJlv6",
    "outputId": "a3cdd498-c621-4e15-a2a3-f3b5106385ba"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 789\n",
    "plt.imshow(Image.fromarray(x_train_org[n]).convert('RGBA'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_E3F1a40xRBJ"
   },
   "source": [
    "\n",
    "Перетворення розмірності даних в наборі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 958
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 511,
     "status": "ok",
     "timestamp": 1572514141230,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "_Mm0LhMvI89W",
    "outputId": "97afd140-185c-4dcb-87d4-1d1cb28f28f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  25 161 209 254 254 255\n",
      "  212 128   3   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 143 254 254 254 254 254\n",
      "  254 254  93   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 146 220 136  56  56 204\n",
      "  254 254 103   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  51 241\n",
      "  254 254  75   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   8  90 248 254\n",
      "  232 143   1   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  44 204 254 254 250\n",
      "   96   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  10 121 254 254 254 254 109\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  51 172 246 254 254 254 254 197  26\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 165 254 254 254 254 254 254 254 215\n",
      "   69   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  78 250 208 125  66 115 233 254 254\n",
      "  175   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4 201 255\n",
      "  254  75   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169 254\n",
      "  254 158   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169 254\n",
      "  254 130   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3 194 254\n",
      "  254  75   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  32   4   0   0   0   0   0   0   0 115 254 254\n",
      "  218   6   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  57 238  96   0   0   0   0   0   5  69 223 254 254\n",
      "  133   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 198 254 143   0   0   0   0  32 199 254 254 254 189\n",
      "   14   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 177 254 252 238 151 151 231 248 254 254 251 134  11\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  19 194 252 254 254 254 254 254 255 214  57   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 114 159 226 254 173 159  66   8   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_org[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 531,
     "status": "ok",
     "timestamp": 1572514226600,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "KY8myUhjJRIi",
    "outputId": "c84dcc96-8f4e-448a-8113-7ccef5239190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(y_train_org[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c_rEv4WNxR-I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.2        0.62352943 0.99215686 0.62352943 0.19607843\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.1882353  0.93333334\n",
      " 0.9882353  0.9882353  0.9882353  0.92941177 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.21176471 0.8901961  0.99215686 0.9882353  0.9372549\n",
      " 0.9137255  0.9882353  0.22352941 0.02352941 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.03921569 0.23529412 0.8784314\n",
      " 0.9882353  0.99215686 0.9882353  0.7921569  0.32941177 0.9882353\n",
      " 0.99215686 0.47843137 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.6392157  0.9882353  0.9882353  0.9882353  0.99215686\n",
      " 0.9882353  0.9882353  0.3764706  0.7411765  0.99215686 0.654902\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.2        0.93333334\n",
      " 0.99215686 0.99215686 0.74509805 0.44705883 0.99215686 0.89411765\n",
      " 0.18431373 0.30980393 1.         0.65882355 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.1882353  0.93333334 0.9882353  0.9882353  0.7019608\n",
      " 0.04705882 0.29411766 0.4745098  0.08235294 0.         0.\n",
      " 0.99215686 0.9529412  0.19607843 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.14901961 0.64705884\n",
      " 0.99215686 0.9137255  0.8156863  0.32941177 0.         0.\n",
      " 0.         0.         0.         0.         0.99215686 0.9882353\n",
      " 0.64705884 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.02745098 0.69803923 0.9882353  0.9411765  0.2784314\n",
      " 0.07450981 0.10980392 0.         0.         0.         0.\n",
      " 0.         0.         0.99215686 0.9882353  0.7647059  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.22352941\n",
      " 0.9882353  0.9882353  0.24705882 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.99215686 0.9882353  0.7647059  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.7764706  0.99215686 0.74509805\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         1.         0.99215686\n",
      " 0.76862746 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.29803923 0.9647059  0.9882353  0.4392157  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.99215686 0.9882353  0.5803922  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.33333334 0.9882353\n",
      " 0.9019608  0.09803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.02745098 0.5294118\n",
      " 0.99215686 0.7294118  0.04705882 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.33333334 0.9882353  0.8745098  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.02745098 0.5137255  0.9882353  0.88235295 0.2784314\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33333334 0.9882353  0.5686275  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.1882353  0.64705884\n",
      " 0.9882353  0.6784314  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.3372549  0.99215686\n",
      " 0.88235295 0.         0.         0.         0.         0.\n",
      " 0.         0.44705883 0.93333334 0.99215686 0.63529414 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.33333334 0.9882353  0.9764706  0.57254905\n",
      " 0.1882353  0.11372549 0.33333334 0.69803923 0.88235295 0.99215686\n",
      " 0.8745098  0.654902   0.21960784 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.33333334 0.9882353  0.9882353  0.9882353  0.8980392  0.84313726\n",
      " 0.9882353  0.9882353  0.9882353  0.76862746 0.50980395 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.10980392 0.78039217\n",
      " 0.9882353  0.9882353  0.99215686 0.9882353  0.9882353  0.9137255\n",
      " 0.5686275  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.09803922 0.5019608  0.9882353\n",
      " 0.99215686 0.9882353  0.5529412  0.14509805 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "#x_train = x_train_org.reshape(60000, 784)\n",
    "#x_test = x_test_org.reshape(10000, 784)\n",
    "x_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AUrlz-dJxSUU"
   },
   "source": [
    "Нормалізація даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XtD8pwo9xSnt"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_train = x_train / 255 \n",
    "x_test = x_test.astype('float32')\n",
    "x_test = x_test / 255 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UXkme9auxS5k"
   },
   "source": [
    "Робота з правильними відповідями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 667,
     "status": "ok",
     "timestamp": 1572514251884,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "USNSIjzlxTNG",
    "outputId": "0a4e7352-86e9-4c19-ecc7-19ceff9e1989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(y_test_org[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KftNP_eGxTlU"
   },
   "source": [
    "\n",
    "Перетворимо мітки в формат one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IlVbJ1h7xT1s"
   },
   "outputs": [],
   "source": [
    "y_train = utils.to_categorical(y_train_org, 10)\n",
    "y_test = utils.to_categorical(y_test_org, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UTPoPcgbxUJI"
   },
   "source": [
    "\n",
    "Правильна відповідь в форматі one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1572514613146,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "S5rm66cAxUYb",
    "outputId": "0bca7717-fc2a-405c-a965-ac5325e55b72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CMqWfajhxUsK"
   },
   "source": [
    "# Створюємо нейронну мережу\n",
    "Створюємо послідовну модель\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "felOtkuvxU8e"
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y0JKeI1ZxVMk"
   },
   "source": [
    "\n",
    "Додаємо рівні мережі\n",
    "\n",
    "Архітектуру мережі взяли за посиланням - https://en.wikipedia.org/wiki/MNIST_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1572514625684,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "-VBMSRlOxVcX",
    "outputId": "b81588a4-a498-4ad0-bd76-08e11b8f794b"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(800, input_dim=784, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZkgYY00yxVqc"
   },
   "source": [
    "\n",
    "Компілюємо мережу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 535,
     "status": "ok",
     "timestamp": 1572514640747,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "tZmK2nkpxV4q",
    "outputId": "52aa7338-7cc6-4694-aa03-7e9280f7c6c1"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bQU2ZJ5GxWG1"
   },
   "source": [
    "\n",
    "Навчаємо нейронну мережу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45076,
     "status": "ok",
     "timestamp": 1572514691831,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "_3WxctN6xWTl",
    "outputId": "a05607b6-3f39-492b-e7dc-44d3aacd2f12"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, \n",
    "                    y_train, \n",
    "                    batch_size=256, \n",
    "                    epochs=10,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "haQy8z-hxWgi"
   },
   "source": [
    "\n",
    "Перевіряємо якість навчання на тестовому наборі даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 984,
     "status": "ok",
     "timestamp": 1572514721524,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "tiUsYWpfxWt3",
    "outputId": "aec16858-bd2a-4a9a-b831-c5ac8011265f"
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fCcBuAbmxW6M"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1023,
     "status": "ok",
     "timestamp": 1572514758286,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "3dRq6AcyxXHd",
    "outputId": "9a010124-b87a-4783-de58-0d80c9c7a09a"
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 683,
     "status": "ok",
     "timestamp": 1572514781481,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "mbHTAsxxxqsD",
    "outputId": "e2f7b12c-a7c5-4327-db00-ea10802808eb"
   },
   "outputs": [],
   "source": [
    "print(\"Доля верных ответов на тестовых данных, в процентах: \", round(scores[1] * 100, 4), \"%\", sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SqD_lWMPxrIj"
   },
   "source": [
    "# Перевірочна вибірка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zG9WXlN-zg0c"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11163,
     "status": "ok",
     "timestamp": 1572514964076,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "aNs-5yPfxre0",
    "outputId": "541252c8-8cb9-4ca5-f8a5-48c48874fe40"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, input_dim=784, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x_train, \n",
    "                    y_train, \n",
    "                    batch_size=200, \n",
    "                    epochs=10,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VjklG0uAxrwb"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G6PTGNWYzjQF"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35640,
     "status": "ok",
     "timestamp": 1572515052958,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "rj4RyuwqxsBD",
    "outputId": "d4efc57c-f8f4-4b9f-efec-e224ca121e68"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(800, input_dim=784, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "nVal = 40000\n",
    "\n",
    "history = model.fit(x_train[:nVal], \n",
    "                    y_train[:nVal], \n",
    "                    batch_size=200, \n",
    "                    epochs=10,\n",
    "                    validation_data=(x_train[nVal:], y_train[nVal:]),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCG6ur1exsWO"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "--nVe0Ed0B_O"
   },
   "source": [
    "**Візуалізація якості навчання**\n",
    "\n",
    "Склад словника History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "KsF8_3pxxslB",
    "outputId": "13983f48-b50e-45f1-d774-ca35f591dd46"
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ijWCVC7xs0g"
   },
   "source": [
    "\n",
    "Друкуємо значення помилки на навчальному наборі даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1572515183435,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "m1srrQE1xtDG",
    "outputId": "ec62b195-22bf-45cd-9053-e228291eff6d"
   },
   "outputs": [],
   "source": [
    "history.history['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OGVjoy0xxtRx"
   },
   "source": [
    "Друкуємо частку правильних відповідей на перевірочному наборі даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 507,
     "status": "ok",
     "timestamp": 1572515190640,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "aOld6utRxtfv",
    "outputId": "58dd0673-c2b0-4392-a2a0-ee75f2e72444"
   },
   "outputs": [],
   "source": [
    "history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KdfCen14xt2X"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 634,
     "status": "ok",
     "timestamp": 1572515198571,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "ThIbZsZRxuDm",
    "outputId": "e96d5663-39a0-4cfb-b96d-0c08780c3ac4"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], \n",
    "         label='Доля вірних відповідей на навчальному наборі')\n",
    "plt.plot(history.history['val_accuracy'], \n",
    "         label='Доля вірних відповідей на перевірочному наборі')\n",
    "plt.xlabel('Епоха навчання')\n",
    "plt.ylabel('Доля вірних відповідей')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YR1_zZBCxuRo"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 765,
     "status": "ok",
     "timestamp": 1572515249332,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "UoRzuQ2gxue_",
    "outputId": "7b8ddb21-bdf9-44d7-b342-c1e0e0e588aa"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], \n",
    "         label='Помилка на навчальному наборі')\n",
    "plt.plot(history.history['val_loss'], \n",
    "         label='Помилка на перевірочному наборі')\n",
    "plt.xlabel('Епоха навчання')\n",
    "plt.ylabel('Помилка')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CYlYahPmxusG"
   },
   "source": [
    "# Перенавчання\n",
    "Без Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 55215,
     "status": "ok",
     "timestamp": 1572515486595,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "q6s33YxTxu6c",
    "outputId": "30ab1456-4121-4a28-d14e-b5648e346689"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(400, input_dim=784, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "nVal = 100\n",
    "\n",
    "history = model.fit(x_train[:nVal], \n",
    "                    y_train[:nVal], \n",
    "                    batch_size=200, \n",
    "                    epochs=10,\n",
    "                    validation_data=(x_train[nVal:], y_train[nVal:]),\n",
    "                    verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'], \n",
    "         label='Доля вірних відповідей на навчальному наборі')\n",
    "plt.plot(history.history['val_accuracy'], \n",
    "         label='Доля вірних відповідей на перевірочному наборі')\n",
    "plt.xlabel('Епоха навчання')\n",
    "plt.ylabel('Доля вірних відповідей')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UBjQqtsptPDo"
   },
   "source": [
    "Стрибки на перших епохах свідчать про те, що модель \"перестрибує\" мінімуми. На навчальній вибірці маємо 100% точність, на перевірочній - лише 60%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4p7okUSsxvF4"
   },
   "source": [
    "**Dropout 30%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57778,
     "status": "ok",
     "timestamp": 1572515833770,
     "user": {
      "displayName": "Nadezhda Nedashkovskaya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB_ZJkTCWgNC5aVqzK-jaE7iVxRAyRTaZuWDlod=s64",
      "userId": "11216524440663778998"
     },
     "user_tz": -120
    },
    "id": "ugNAUyYgxvR2",
    "outputId": "782d5e42-783b-40ef-ca67-37b936e98b14"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(400, input_dim=784, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "# Выходной полносвязный слой, 10 нейронов (по количеству рукописных цифр)\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "#model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=1e-1), metrics=[\"accuracy\"])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "nVal = 100\n",
    "\n",
    "history = model.fit(x_train[:nVal], \n",
    "                    y_train[:nVal], \n",
    "                    batch_size=200, \n",
    "                    epochs=50,\n",
    "                    validation_data=(x_train[nVal:], y_train[nVal:]),\n",
    "                    verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'], \n",
    "         label='Доля вірних відповідей на навчальному наборі')\n",
    "plt.plot(history.history['val_accuracy'], \n",
    "         label='Доля вірних відповідей на перевірочному наборі')\n",
    "plt.xlabel('Епоха навчання')\n",
    "plt.ylabel('Доля вірних відповідей')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zvoPGk1EtAjE"
   },
   "source": [
    "Отримали, що без дропаута точність на перевірочній вибірці була 60%, а з дропаутом (0.3) вона підвищилася і стала 66%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DztJ6IGX3A8m"
   },
   "source": [
    "**Dropout 80%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRCgXQJk3Bcw"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(400, input_dim=784, activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "# Выходной полносвязный слой, 10 нейронов (по количеству рукописных цифр)\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "nVal = 100\n",
    "\n",
    "history = model.fit(x_train[:nVal], \n",
    "                    y_train[:nVal], \n",
    "                    batch_size=200, \n",
    "                    epochs=50,\n",
    "                    validation_data=(x_train[nVal:], y_train[nVal:]),\n",
    "                    verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'], \n",
    "         label='Доля вірних відповідей на навчальному наборі')\n",
    "plt.plot(history.history['val_accuracy'], \n",
    "         label='Доля вірних відповідей на перевірочному наборі')\n",
    "plt.xlabel('Епоха навчання')\n",
    "plt.ylabel('Доля вірних відповідей')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ws3NLyGGs0tc"
   },
   "source": [
    "Отримали, що при дропауті(0.8) точність на перевірочній вибірці дорівнює 60% - така ж як і без дропаута. Проте зараз точність на навчальній вибірці різко зменшилася і сильно коливається."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5koDnCXP3Bwj"
   },
   "source": [
    "**Dropout 10%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "In8KjN853CGj"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(400, input_dim=784, activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "# Выходной полносвязный слой, 10 нейронов (по количеству рукописных цифр)\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "nVal = 100\n",
    "\n",
    "history = model.fit(x_train[:nVal], \n",
    "                    y_train[:nVal], \n",
    "                    batch_size=200, \n",
    "                    epochs=50,\n",
    "                    validation_data=(x_train[nVal:], y_train[nVal:]),\n",
    "                    verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'], \n",
    "         label='Доля вірних відповідей на навчальному наборі')\n",
    "plt.plot(history.history['val_accuracy'], \n",
    "         label='Доля вірних відповідей на перевірочному наборі')\n",
    "plt.xlabel('Епоха навчання')\n",
    "plt.ylabel('Доля вірних відповідей')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ob48YRbGrhLH"
   },
   "source": [
    "З дропаутом(0.1) точність на навчальній вибірці 100%, на перевірочній вибірці 68%, без дропаута була 60%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KUHsgMTZ3Cce"
   },
   "source": [
    "# Нормалізація за міні-батчами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NM6H7pDKrOpF",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(400, input_dim=784, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "# Выходной полносвязный слой, 10 нейронов (по количеству рукописных цифр)\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "nVal = 100\n",
    "\n",
    "history = model.fit(x_train[:nVal], \n",
    "                    y_train[:nVal], \n",
    "                    batch_size=200, \n",
    "                    epochs=50,\n",
    "                    validation_data=(x_train[nVal:], y_train[nVal:]),\n",
    "                    verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'], \n",
    "         label='Доля вірних відповідей на навчальному наборі')\n",
    "plt.plot(history.history['val_accuracy'], \n",
    "         label='Доля вірних відповідей на перевірочному наборі')\n",
    "plt.xlabel('Епоха навчання')\n",
    "plt.ylabel('Доля вірних відповідей')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Or4Qiv54yWc"
   },
   "source": [
    "# Функції активації"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Me7EPnM_3Cyy"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Входной полносвязный слой, 800 нейронов, 784 входа в каждый нейрон\n",
    "model.add(Dense(100, input_dim=784, activation=\"softmax\"))\n",
    "#model.add(Dropout(0.2))\n",
    "# Выходной полносвязный слой, 10 нейронов (по количеству рукописных цифр)\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x_train, \n",
    "                    y_train, \n",
    "                    batch_size=200, \n",
    "                    epochs=20,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'], \n",
    "         label='Доля вірних відповідей на навчальному наборі')\n",
    "plt.plot(history.history['val_accuracy'], \n",
    "         label='Доля вірних відповідей на перевірочному наборі')\n",
    "plt.xlabel('Епоха навчання')\n",
    "plt.ylabel('Доля вірних відповідей')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-HdFlN7F3DFD"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "og3-ZV8j5e9c"
   },
   "source": [
    "# Усереднення точності мережі за кількома ітераціями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MOOCY1iO3DVV"
   },
   "outputs": [],
   "source": [
    "valAcc = []\n",
    "iterations = 10\n",
    "\n",
    "for i in range(iterations):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Входной полносвязный слой, 800 нейронов, 784 входа в каждый нейрон\n",
    "    model.add(Dense(10, input_dim=784, activation=\"relu\"))\n",
    "    #model.add(Dropout(0.2))\n",
    "    # Выходной полносвязный слой, 10 нейронов (по количеству рукописных цифр)\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(x_train, \n",
    "                        y_train, \n",
    "                        batch_size=200, \n",
    "                        epochs=5,\n",
    "                        validation_split=0.2,\n",
    "                        verbose=0)\n",
    "  \n",
    "    currAcc = history.history['val_accuracy'][-1]\n",
    "    valAcc.append(currAcc)\n",
    "    print(\"Запуск\", i, \"точність\", currAcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZXG8vfFT5gFQ"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dHCxkicR6OaS"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjytC8i-5gav"
   },
   "outputs": [],
   "source": [
    "valAcc = np.array(valAcc)\n",
    "meanAcc = sum(valAcc) / valAcc.shape[0]\n",
    "print(meanAcc)\n",
    "print(max(valAcc) - min(valAcc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PRUzoBDv5grX"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LECUw03q5hQh"
   },
   "source": [
    "\n",
    "# Запуск декількох мереж"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OE3lNoEn5hfa"
   },
   "outputs": [],
   "source": [
    "def evaluateModel(model, batchSize, epohs, valSplit):\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(x_train, \n",
    "                        y_train, \n",
    "                        batch_size=batchSize, \n",
    "                        epochs=epohs,\n",
    "                        validation_split=valSplit,\n",
    "                        verbose=0)\n",
    "  \n",
    "    currAcc = history.history['val_accuracy'][-1]\n",
    "  \n",
    "    return currAcc, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ZDljg2l5huN"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HlxCSKSi5h5s"
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=784, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "models.append(model)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=784, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "models.append(model)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=784, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "models.append(model)\n",
    "\n",
    "batchSisez = [100, 200, 300]\n",
    "\n",
    "acc = []\n",
    "hist = []\n",
    "for i in range(len(models)):\n",
    "    currAcc, currHistory = evaluateModel(models[i], batchSisez[i], 5, 0.2)\n",
    "    acc.append(currAcc)\n",
    "    hist.append(currHistory)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AAM74iob650Y"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9a9ciT4m66EN"
   },
   "outputs": [],
   "source": [
    "print(hist[0].history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V9wZRF7T66bj"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5KxUtBRt66or"
   },
   "source": [
    "# Load my picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model4.dump\", monitor='val_loss', verbose=1, save_best_only=True, \n",
    "                             save_weights_only=True, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 800)               628000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 800)               3200      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               102528    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 735,018\n",
      "Trainable params: 733,418\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/30\n",
      "47600/48000 [============================>.] - ETA: 0s - loss: 0.2498 - accuracy: 0.9290\n",
      "Epoch 00001: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 0.2488 - accuracy: 0.9294 - val_loss: 0.1971 - val_accuracy: 0.9553\n",
      "Epoch 2/30\n",
      "47400/48000 [============================>.] - ETA: 0s - loss: 0.0941 - accuracy: 0.9712\n",
      "Epoch 00002: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0943 - accuracy: 0.9711 - val_loss: 0.1226 - val_accuracy: 0.9641\n",
      "Epoch 3/30\n",
      "47400/48000 [============================>.] - ETA: 0s - loss: 0.0592 - accuracy: 0.9809\n",
      "Epoch 00003: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.0592 - accuracy: 0.9809 - val_loss: 0.1347 - val_accuracy: 0.9623\n",
      "Epoch 4/30\n",
      "47400/48000 [============================>.] - ETA: 0s - loss: 0.0492 - accuracy: 0.9840\n",
      "Epoch 00004: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0491 - accuracy: 0.9840 - val_loss: 0.1427 - val_accuracy: 0.9621\n",
      "Epoch 5/30\n",
      "47600/48000 [============================>.] - ETA: 0s - loss: 0.0384 - accuracy: 0.9876\n",
      "Epoch 00005: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0385 - accuracy: 0.9875 - val_loss: 0.1280 - val_accuracy: 0.9676\n",
      "Epoch 6/30\n",
      "47800/48000 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9886\n",
      "Epoch 00006: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0339 - accuracy: 0.9886 - val_loss: 0.1240 - val_accuracy: 0.9693\n",
      "Epoch 7/30\n",
      "47800/48000 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9912\n",
      "Epoch 00007: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.0261 - accuracy: 0.9912 - val_loss: 0.1276 - val_accuracy: 0.9713\n",
      "Epoch 8/30\n",
      "47400/48000 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9907\n",
      "Epoch 00008: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.0276 - accuracy: 0.9907 - val_loss: 0.1158 - val_accuracy: 0.9734\n",
      "Epoch 9/30\n",
      "47400/48000 [============================>.] - ETA: 0s - loss: 0.0236 - accuracy: 0.9923\n",
      "Epoch 00009: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.1159 - val_accuracy: 0.9745\n",
      "Epoch 10/30\n",
      "47800/48000 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9935\n",
      "Epoch 00010: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.0194 - accuracy: 0.9934 - val_loss: 0.1189 - val_accuracy: 0.9746\n",
      "Epoch 11/30\n",
      "47400/48000 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9945\n",
      "Epoch 00011: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.1334 - val_accuracy: 0.9724\n",
      "Epoch 12/30\n",
      "47600/48000 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9958\n",
      "Epoch 00012: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.1173 - val_accuracy: 0.9758\n",
      "Epoch 13/30\n",
      "47400/48000 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9953\n",
      "Epoch 00013: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.1307 - val_accuracy: 0.9729\n",
      "Epoch 14/30\n",
      "47600/48000 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9937\n",
      "Epoch 00014: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.1564 - val_accuracy: 0.9718\n",
      "Epoch 15/30\n",
      "47600/48000 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.9944\n",
      "Epoch 00015: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.1252 - val_accuracy: 0.9752\n",
      "Epoch 16/30\n",
      "47800/48000 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9940\n",
      "Epoch 00016: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 106us/sample - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.1354 - val_accuracy: 0.9744\n",
      "Epoch 17/30\n",
      "47600/48000 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9942\n",
      "Epoch 00017: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 101us/sample - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.1349 - val_accuracy: 0.9743\n",
      "Epoch 18/30\n",
      "47400/48000 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9954\n",
      "Epoch 00018: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.1488 - val_accuracy: 0.9734\n",
      "Epoch 19/30\n",
      "47800/48000 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9963\n",
      "Epoch 00019: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.1435 - val_accuracy: 0.9757\n",
      "Epoch 20/30\n",
      "47800/48000 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 00020: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.1315 - val_accuracy: 0.9759\n",
      "Epoch 21/30\n",
      "47800/48000 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9958\n",
      "Epoch 00021: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.1544 - val_accuracy: 0.9754\n",
      "Epoch 22/30\n",
      "47800/48000 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9968\n",
      "Epoch 00022: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.1462 - val_accuracy: 0.9769\n",
      "Epoch 23/30\n",
      "47400/48000 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9965\n",
      "Epoch 00023: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.1463 - val_accuracy: 0.9779\n",
      "Epoch 24/30\n",
      "47800/48000 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9968\n",
      "Epoch 00024: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.1469 - val_accuracy: 0.9769\n",
      "Epoch 25/30\n",
      "47800/48000 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9967\n",
      "Epoch 00025: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.1504 - val_accuracy: 0.9745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "47600/48000 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9955\n",
      "Epoch 00026: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 101us/sample - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.1543 - val_accuracy: 0.9754\n",
      "Epoch 27/30\n",
      "47400/48000 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9958\n",
      "Epoch 00027: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 101us/sample - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.1511 - val_accuracy: 0.9758\n",
      "Epoch 28/30\n",
      "47400/48000 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9971\n",
      "Epoch 00028: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 101us/sample - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.1455 - val_accuracy: 0.9774\n",
      "Epoch 29/30\n",
      "47800/48000 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9979\n",
      "Epoch 00029: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.1343 - val_accuracy: 0.9789\n",
      "Epoch 30/30\n",
      "47400/48000 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9981\n",
      "Epoch 00030: val_loss did not improve from 0.10397\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.1319 - val_accuracy: 0.9793\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Входной полносвязный слой, 800 нейронов, 784 входа в каждый нейрон\n",
    "model.add(Dense(800, input_dim=784, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.2))\n",
    "# Выходной полносвязный слой, 10 нейронов (по количеству рукописных цифр)\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, \n",
    "                    y_train, \n",
    "                    batch_size=200, \n",
    "                    epochs=30,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[checkpoint],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2c801b33f98>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"model4.dump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open('7_2.png').convert(\"L\")\n",
    "plt.imshow(img.convert('RGBA'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  36  79   1   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  19  74 141 158 147 147 151 154 146\n",
      "  123   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  57\n",
      "   60   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 166\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  55  91\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 161   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  31 108   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 168   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  12 118   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 105   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 111   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 113   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 111   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  91   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  26  63   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  90   8   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 102   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  89   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 105   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  98   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  99   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 118   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "pix = np.array(img)\n",
    "print(pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix = pix.reshape(1, 784)\n",
    "pix = pix.astype('float32')\n",
    "pix = pix / 255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(pix)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000268355 0.11825 0.00155931 0.0116662 0.000983592 0.854674\n",
      "  9.19272e-05 0.0114322 1.62749e-05 0.00105797]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={\"float_kind\": lambda x: \"%g\" % x})\n",
    "\n",
    "y_pred = model.predict(pix)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "KA_66_Lab_3_Quality_NeuroNet_OverFitting_MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
